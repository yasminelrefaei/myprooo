#VERSION1
import streamlit as st
from transformers import pipeline

st.title("ğŸ’¬ Mental Health Chat Assistant")
st.write("This is a simple NLP-based chatbot to provide **supportive responses** for mental health related conversations.")

# Load pretrained model
@st.cache_resource
def load_model():
    return pipeline("text-generation", model="gpt2")

chat_model = load_model()

# Initialize session state for chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# User input
user_input = st.text_input("You:", "")

if st.button("Send"):
    if user_input.strip() != "":
        # Add user message
        st.session_state.messages.append(("You", user_input))

        # Generate AI response
        response = chat_model(user_input, max_length=100, num_return_sequences=1, do_sample=True)
        bot_reply = response[0]["generated_text"]

        # Clean reply (optional: cut after first sentence)
        if "." in bot_reply:
            bot_reply = bot_reply.split(".")[0] + "."

        st.session_state.messages.append(("Assistant", bot_reply))

# Display chat history
st.subheader("Conversation")
for sender, msg in st.session_state.messages:
    if sender == "You":
        st.markdown(f"**{sender}:** {msg}")
    else:
        st.markdown(f"<div style='background-color:#e8f4f8;padding:8px;border-radius:10px;'><b>{sender}:</b> {msg}</div>", unsafe_allow_html=True)


########################################################################################################33
#VERSIN2
# import streamlit as st
# from transformers import pipeline

# st.set_page_config(page_title="Mental Health Chat Assistant", page_icon="ğŸ’¬")

# st.title("ğŸ’¬ Mental Health Chat Assistant")
# st.caption(
#     "Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯ Ø¯Ø§Ø¹Ù… ÙˆÙ„Ø³Øª Ù…Ø®ØªØµÙ‹Ø§ Ø·Ø¨ÙŠÙ‹Ø§. Ù„Ùˆ ÙÙŠ Ø®Ø·Ø± ÙÙˆØ±ÙŠ Ø£Ùˆ ØªÙÙƒÙŠØ± Ø¨Ø¥ÙŠØ°Ø§Ø¡ Ø§Ù„Ù†ÙØ³ØŒ "
#     "Ù…Ù† ÙØ¶Ù„Ùƒ ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ø¬Ù‡Ø§Øª Ø§Ù„Ø·Ø¨ÙŠØ© Ø£Ùˆ Ø§Ù„Ø·ÙˆØ§Ø±Ø¦ Ø§Ù„Ù…Ø­Ù„ÙŠØ© ÙÙˆØ±Ù‹Ø§."
# )

# # --------- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¹Ø§Ù…Ø© ---------
# SYSTEM_PROMPT = (
#     "You are a supportive, empathetic mental health chat assistant. "
#     "Your style: brief, gentle, non-judgmental. "
#     "Do NOT diagnose or give medical instructions. "
#     "Acknowledge feelings, encourage seeking professional help, "
#     "and suggest simple, safe coping steps (e.g., breathing, journaling, talking to a trusted person). "
#     "If the user mentions self-harm or immediate danger, encourage contacting local emergency services."
# )

# CRISIS_KEYWORDS = [
#     "suicide", "kill myself", "self-harm", "hurt myself",
#     "Ø§Ù†ØªØ­Ø§Ø±", "Ø£Ø¤Ø°ÙŠ Ù†ÙØ³ÙŠ", "Ø§ÙŠØ°Ø§Ø¡ Ù†ÙØ³ÙŠ", "Ù‚ØªÙ„ Ù†ÙØ³ÙŠ"
# ]

# # --------- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ ÙƒØ§Ø´ ---------
# @st.cache_resource(show_spinner=True)
# def load_model():
#     # Ù…Ù„Ø§Ø­Ø¸Ø©: gpt2 Ù†Ù…ÙˆØ°Ø¬ ØªÙƒÙ…Ù„Ø© Ø¹Ø§Ù…Ø©Ø› Ù„Ø£Ø¯Ø§Ø¡ Ø£ÙØ¶Ù„ ÙÙƒÙ‘Ø± ÙÙŠ Ù†Ù…ÙˆØ°Ø¬ Ø¯Ø±Ø¯Ø´Ø© Ù…ÙØ¹Ù„Ù… (instruct/chat) Ù„Ø§Ø­Ù‚Ù‹Ø§.
#     text_gen = pipeline("text-generation", model="gpt2")
#     # Ø¶Ø¨Ø· pad_token_id Ù„ØªÙØ§Ø¯ÙŠ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ù…Ø¹ GPT-2
#     try:
#         text_gen.tokenizer.pad_token = text_gen.tokenizer.eos_token
#     except Exception:
#         pass
#     return text_gen

# chat_model = load_model()

# # --------- Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø© ---------
# if "messages" not in st.session_state:
#     # Ø³Ù†Ø®Ø²Ù† Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ ÙƒÙ‚ÙˆØ§Ù…ÙŠØ³ role/content Ù„ØªØ³Ù‡ÙŠÙ„ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª
#     st.session_state.messages = [
#         {"role": "system", "content": SYSTEM_PROMPT}
#     ]

# # --------- Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© ---------
# def looks_like_crisis(text: str) -> bool:
#     t = text.lower()
#     return any(k in t for k in CRISIS_KEYWORDS)

# def build_prompt_from_history():
#     """
#     Ù†Ø¨Ù†ÙŠ Ø¨Ø±ÙˆÙ…Ø¨Øª Ø¨Ø³ÙŠØ· Ù…Ù† Ø¢Ø®Ø± 6 ØªØ¨Ø§Ø¯Ù„Ø§Øª (Ù„Ù…Ù†Ø¹ Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø²Ø§Ø¦Ø¯).
#     Ø§Ù„ØµÙŠØºØ©: System + (User/Assistant Ø¨Ø¯ÙˆØ±Ù‡Ù…) + 'Assistant:'
#     """
#     history = st.session_state.messages[-12:]  # ØªÙ‚Ø±ÙŠØ¨Ù‹Ø§ 6 ØªØ¨Ø§Ø¯Ù„Ø§Øª
#     lines = []
#     for m in history:
#         if m["role"] == "system":
#             lines.append(f"System: {m['content']}")
#         elif m["role"] == "user":
#             lines.append(f"You: {m['content']}")
#         elif m["role"] == "assistant":
#             lines.append(f"Assistant: {m['content']}")
#     lines.append("Assistant:")
#     return "\n".join(lines)

# def generate_reply(user_text: str) -> str:
#     # ØªØ¹Ø§Ù…Ù„ Ø®Ø§Øµ Ù…Ø¹ Ø§Ù„Ø£Ø²Ù…Ø§Øª
#     if looks_like_crisis(user_text):
#         return (
#             "Ø£Ù†Ø§ Ø¢Ø³Ù Ø¥Ù†Ùƒ Ø¨ØªÙ…Ø±Ù‘ Ø¨Ø´Ø¹ÙˆØ± ØµØ¹Ø¨. Ù„Ùˆ ÙÙŠ Ø®Ø·Ø± ÙÙˆØ±ÙŠ Ø£Ùˆ Ø£ÙÙƒØ§Ø± Ù„Ø¥ÙŠØ°Ø§Ø¡ Ù†ÙØ³ÙƒØŒ "
#             "Ù…Ù† ÙØ¶Ù„Ùƒ ØªÙˆØ§ØµÙ„ Ø§Ù„Ø¢Ù† Ù…Ø¹ Ø§Ù„Ø·ÙˆØ§Ø±Ø¦ Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø£Ùˆ Ø¬Ù‡Ø© Ø¯Ø¹Ù… Ù‚Ø±ÙŠØ¨Ø© Ù…Ù†Ùƒ. "
#             "Ù„Ùˆ ØªÙ‚Ø¯Ø±ØŒ Ø§Ø­ÙƒÙŠ Ù„Ø´Ø®Øµ Ù…ÙˆØ«ÙˆÙ‚ Ù‚Ø±ÙŠØ¨ Ù…Ù†Ùƒ Ø£Ùˆ ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ù…Ø®ØªØµ/Ø©."
#         )
#     prompt = build_prompt_from_history()
#     # Ù†Ø·Ù„Ø¨ ÙÙ‚Ø· Ø§Ù„ØªÙƒÙ…Ù„Ø© (Ø¨Ø¯ÙˆÙ† ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„) ÙˆÙ†Ø­Ø¯ Ø¹Ø¯Ø¯ Ø§Ù„ØªÙˆÙƒÙÙ†Ø² Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
#     out = chat_model(
#         prompt,
#         max_new_tokens=120,
#         do_sample=True,
#         temperature=0.8,
#         top_p=0.9,
#         repetition_penalty=1.2,
#         no_repeat_ngram_size=3,
#         return_full_text=False,  # <-- Ù…Ù‡Ù…!
#         eos_token_id=chat_model.tokenizer.eos_token_id,
#         pad_token_id=chat_model.tokenizer.eos_token_id,
#     )
#     text = out[0]["generated_text"].strip()

#     # ØªÙ†Ø¸ÙŠÙ Ø¨Ø³ÙŠØ·: ÙˆÙ‚Ù Ø¹Ù†Ø¯ Ø£ÙˆÙ„ Ù†Ù‡Ø§ÙŠØ© Ø¬Ù…Ù„Ø© Ù…Ø¹Ù‚ÙˆÙ„Ø©
#     for stop in [".", "!", "ØŸ", "â€¦"]:
#         if stop in text:
#             text = text.split(stop)[0].strip() + stop
#             break

#     # fallback Ù„Ùˆ Ø§Ù„Ù†Øµ Ù‚ØµÙŠØ± Ø¬Ø¯Ù‹Ø§
#     if len(text) < 2:
#         text = "Ù…ØªÙÙ‡Ù… Ø¥Ø­Ø³Ø§Ø³Ùƒ. Ù…Ù…ÙƒÙ† ØªØ­ÙƒÙŠÙ„ÙŠ Ø£ÙƒØªØ±ØŸ Ø£Ù†Ø§ Ù‡Ù†Ø§ Ø¹Ù„Ø´Ø§Ù† Ø£Ø³Ù…Ø¹Ùƒ."

#     return text

# # --------- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ---------
# # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ø£Ø­Ø¯Ø«
# for m in st.session_state.messages:
#     if m["role"] == "user":
#         with st.chat_message("user"):
#             st.markdown(m["content"])
#     elif m["role"] == "assistant":
#         with st.chat_message("assistant"):
#             st.markdown(m["content"])

# user_input = st.chat_input("Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§â€¦")

# if user_input:
#     # Ø£Ø¶Ù Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
#     st.session_state.messages.append({"role": "user", "content": user_input})
#     with st.chat_message("user"):
#         st.markdown(user_input)

#     # ÙˆÙ„Ù‘Ø¯ Ø§Ù„Ø±Ø¯
#     reply = generate_reply(user_input)

#     # Ø£Ø¶Ù ÙˆØ¹Ø±Ø¶ Ø±Ø¯ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯
#     st.session_state.messages.append({"role": "assistant", "content": reply})
#     with st.chat_message("assistant"):
#         st.markdown(reply)
